{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuertascompany/Saas-Fee/blob/main/hands-on/chapter3/Galaxy_Morphology_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jatIhJ9KJQV"
      },
      "source": [
        "#Galaxy Morphology with CNNs\n",
        "\n",
        "The goal of this tutorial is to illustrate a very basic supervised binary classification with CNNs. The goal is to setup a ML algorithm to determine the visual morphological type of nearby galaxies from the Sloan Digital Sky Survey. The first deep learning papers in Astronomy addressed this problem at low and high redshift (Dielemann+15, Huertas-Company+15).\n",
        "\n",
        "![](https://drive.google.com/uc?id=1TaiRB1wxui4AKnhuF4iH4LJkmrlb-D6d)\n",
        "\n",
        "\n",
        "\n",
        "We use a Convolutional Neural Network (deep learning) to learn the features directly from the images with no catalog information. The CNN  model is implemented here with Keras and a TensorFlow backend.  We use as training set, the visually classified sample of ~14,000 galaxies by Nair&Abraham. For illustration purposes, we use jpeg RGB images as input. However the same methodology can be applied to fits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpv-XO8Sxgvi"
      },
      "source": [
        "import numpy as np\n",
        "from astropy.io import fits\n",
        "from astropy.table import Table\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, accuracy_score,auc\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tfkl = tf.keras.layers\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PqZCKlVSMJ"
      },
      "source": [
        "## Mount Drive\n",
        "\n",
        "Before mounting the drive click on [this folder](https://drive.google.com/drive/folders/1PcftgBzBySo1Ync-Wdsp9arTCJ_MfEPE?usp=sharing) and add it to your google drive by following these steps:\n",
        "\n",
        "*   Go to your drive\n",
        "*   Find shared folder (\"Shared with me\" link)\n",
        "*   Right click it\n",
        "*   Click Add to My Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Io82GXlCNdF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqPFZXvf1FNs"
      },
      "source": [
        "---\n",
        "#### The notenook is setup to illustrate 2 different classifications:\n",
        "\n",
        "\n",
        "#### 1.   Early vs. Late: This is an easy example in which we only try to separate between early-type and late-type galaxies.\n",
        "\n",
        "#### 2.   E vs. S0: The second example is more challenging. We try to separate ellipticals from S0s.\n",
        "\n",
        "#### By default case 1 is turn on. In order to switch to case 2 set the variable CLASS_EARLY_LATE to False.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM9KbCzH21D_"
      },
      "source": [
        "CLASS_EARLY_LATE=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A5hM83EeiH5"
      },
      "source": [
        "## Deep Learning (CNN)\n",
        "This section illustrates how to use a Convolutional Neural Network to estimate the visual morphology. The input of the network are now the images themselves without parameters. The CNN then automatically extracts the features. This is the main difference between classical and deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OErN1Sb5enXV"
      },
      "source": [
        "### Data Download and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhIqCwEg9UUd"
      },
      "source": [
        "if CLASS_EARLY_LATE:\n",
        "  #Load data\n",
        "  pathinData=\"/content/drive/MyDrive/ED127_2023/morphology\"\n",
        "\n",
        "  #images\n",
        "  X = np.load(pathinData+'/image_vector_E_S_10000.npy')\n",
        "  #morphological class\n",
        "  Y = np.load(pathinData+'/target_vector_E_S_10000.npy')\n",
        "\n",
        "else:\n",
        "  #Load data\n",
        "  pathinData=\"/content/drive/MyDrive/ED127_2023/morphology\"\n",
        "\n",
        "  #images\n",
        "  X = np.load(pathinData+'/image_vector_E_S0_5250.npy')\n",
        "  #morphological class\n",
        "  Y = np.load(pathinData+'/target_vector_E_S0_5250.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7JrTFYZz96c"
      },
      "source": [
        "# Spliting in Training and Test datasets, 4/5 of galaxies for training, 1/5 for testing\n",
        "x_train = X[0:len(X)//5*3,:,:,:]\n",
        "x_val = X[len(X)//5*3:len(X)//5*4,:,:,:]\n",
        "x_test = X[len(X)//5*4:,:,:,:]\n",
        "t_train = Y[0:len(Y)//5*3]\n",
        "t_val = Y[len(Y)//5*3:len(Y)//5*4]\n",
        "t_test = Y[len(Y)//5*4:]\n",
        "print ('Y_train.shape= ', t_train.shape)\n",
        "print(np.max(t_train),np.min(t_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c80101gQ5f2J"
      },
      "source": [
        "### Visualization of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKdVzDtN3dkw"
      },
      "source": [
        "randomized_inds_train = np.random.permutation(len(x_train))\n",
        "\n",
        "fig = plt.figure()\n",
        "for i,j in zip(randomized_inds_train[0:4],range(4)):\n",
        "  ax = fig.add_subplot(2, 2, j+1)\n",
        "  im = ax.imshow(x_train[i,:,:].astype(int))\n",
        "  plt.title('$Morph$='+str(t_train[i]))\n",
        "  fig.tight_layout()\n",
        "  fig.colorbar(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8HpW3HM5mAP"
      },
      "source": [
        "### Pre-processing of images (Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lIPKj4l_rXQ"
      },
      "source": [
        "mu = np.amax(x_train,axis=(1,2))\n",
        "for i in range(0,mu.shape[0]):\n",
        "    x_train[i,:,:,0] = x_train[i,:,:,0]/mu[i,0]\n",
        "    x_train[i,:,:,1] = x_train[i,:,:,1]/mu[i,1]\n",
        "    x_train[i,:,:,2] = x_train[i,:,:,2]/mu[i,2]\n",
        "\n",
        "mu_test = np.amax(x_test,axis=(1,2))\n",
        "for i in range(0,mu_test.shape[0]):\n",
        "    x_test[i,:,:,0] = x_test[i,:,:,0]/mu_test[i,0]\n",
        "    x_test[i,:,:,1] = x_test[i,:,:,1]/mu_test[i,1]\n",
        "    x_test[i,:,:,2] = x_test[i,:,:,2]/mu_test[i,2]\n",
        "\n",
        "mu_val = np.amax(x_val,axis=(1,2))\n",
        "for i in range(0,mu_val.shape[0]):\n",
        "    x_val[i,:,:,0] = x_val[i,:,:,0]/mu_val[i,0]\n",
        "    x_val[i,:,:,1] = x_val[i,:,:,1]/mu_val[i,1]\n",
        "    x_val[i,:,:,2] = x_val[i,:,:,2]/mu_val[i,2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8H-WZHXLlK4"
      },
      "source": [
        "### Model definition\n",
        "The following cell defines the model architecture. There is a Convolutional part made of multiple convolutinal layers with differnet depths and filter sizes. MaxPooling are used to reduce the sizes of tensors as we go deeper into the network. Batch Normalization and Dropout are use at the training phase to reduce over fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx-BT4zM348O"
      },
      "source": [
        "def CNN_Nair(img_channels, img_rows, img_cols):\n",
        "    # some hyperparamters you can chage\n",
        "    dropoutpar=0.5\n",
        "    depth=16\n",
        "    nb_dense = 64\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "    tfkl.Input(shape=(img_rows,img_cols,img_channels)),\n",
        "    tfkl.Conv2D(filters=32, kernel_size=(6,6), activation='relu',padding='same'),\n",
        "    ## COMPLETE HERE WITH MORE LAYERS\n",
        "    tfkl.Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    print(\"Compilation...\")\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    print(\"... done!\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvFhx7oEB-tP"
      },
      "source": [
        "model = CNN_Nair(3,69,69)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFKDX1PtP4x7"
      },
      "source": [
        "This cell is to delete prevois runs if needed. Only run if you want to delete the results from previous runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FO8dzy8DdQY"
      },
      "source": [
        "RESET=True\n",
        "if RESET:\n",
        "  os.system(\"rm -r \"+pathout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjEmToBYRaJJ"
      },
      "source": [
        "Main code for training the CNN model defined previously. All outputs are stored in pathout. Change if you want to keep different models. BY default the dataset is augmented to reduce overfitting. You can turn it off be setting data_augmentation to False."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gh5bQhF98Gq"
      },
      "source": [
        "# train params - hardocded for simplicity - you can change them\n",
        "pathout='morphology/models/model1' #output folder to store the results\n",
        "model_name = '/cnn1'  #name of the final model which is saved in pathout\n",
        "\n",
        "LOAD_MODEL=False\n",
        "\n",
        "batch_size = 64\n",
        "nb_epoch = 5  #number of iterations for training - Can be changed\n",
        "data_augmentation = False # if set to True the data will be augmented at every iteration\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = x_train.shape[1:3]\n",
        "img_channels = 3\n",
        "\n",
        "\n",
        "#build model\n",
        "cnn=CNN_Nair(img_channels, img_rows, img_cols)\n",
        "if LOAD_MODEL:\n",
        "  cnn.load_weights(pathout+model_name+'.hd5')\n",
        "\n",
        "\n",
        "if not data_augmentation:\n",
        "  print('Not using data augmentation.')\n",
        "  history = cnn.fit(x_train, t_train,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=nb_epoch,\n",
        "                            validation_data=(x_val, t_val),\n",
        "                            shuffle=True)\n",
        "else:\n",
        "  print('Using real-time data augmentation.')\n",
        "\n",
        "  # this will do preprocessing and realtime data augmentation. FEEL FREE TO\n",
        "  # CHANGE THE PARAMETERS AND SEE THE EFFECTS\n",
        "  datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,\n",
        "            samplewise_center=False,\n",
        "            featurewise_std_normalization=False,\n",
        "            samplewise_std_normalization=False,\n",
        "            zca_whitening=False,\n",
        "            rotation_range=25,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            zoom_range=[0.75,1.3])\n",
        "\n",
        "\n",
        "  #datagen.fit(x_train)\n",
        "\n",
        "  history = cnn.fit(\n",
        "                    datagen.flow(x_train, t_train, batch_size=batch_size),\n",
        "                    epochs=nb_epoch,\n",
        "                    validation_data=(x_val, t_val),\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "print(\"Saving model...\")\n",
        "cnn.save_weights(pathout+model_name+\".hd5\",overwrite=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell visualizes the training history"
      ],
      "metadata": {
        "id": "xjyQ3-2UKX5Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfRPjByfWDZ4"
      },
      "source": [
        "plot(history.history['loss'])\n",
        "plot(history.history['val_loss'],color='red')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6jXNmKDGcyo"
      },
      "source": [
        "## Predictions and comparisons of different approaches\n",
        "The following cells use the trained model to predict the morphological class of the test dataset and compare the performance of the different algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFpihOh0FuN2"
      },
      "source": [
        "print(\"Predicting...\")\n",
        "print(\"====================\")\n",
        "LOAD_MODEL=False\n",
        "if LOAD_MODEL:\n",
        "  cnn = tf.keras.models.load_model(pathout+model_name+\".hd5\")\n",
        "\n",
        "Y_pred_DL = cnn.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXKSAhBqSX2g"
      },
      "source": [
        "We now compute the global accuracy as well as ROC and P-R curves. If you are not familiar with these curves please see the lecture slides or click [here](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svvKwV-AGpYB"
      },
      "source": [
        "#global accuracy\n",
        "\n",
        "## TRY DIFFERENT MODELS - SEE THE EFFECTS ON THE FINAL ROC CURVES\n",
        "\n",
        "## COMPARE IN A UNIQUE NOTEBOOK THE 3 METHODS WE HAVE SEEN\n",
        "## COMMENT\n",
        "\n",
        "\n",
        "Y_pred_DL_class=Y_pred_DL*0\n",
        "Y_pred_DL_class[Y_pred_DL>0.5]=1\n",
        "\n",
        "print(\"Global Accuracy CNN:\", accuracy_score(t_test, Y_pred_DL_class))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ROC curve (False positive rate vs. True positive rate)\n",
        "fpr_DL, tpr_DL, thresholds_DL = roc_curve(t_test, Y_pred_DL)\n",
        "\n",
        "print(\"AUC CNN:\", auc(fpr_DL, tpr_DL))\n",
        "\n",
        "#plot ROC\n",
        "fig = plt.figure()\n",
        "plt.title('ROC curve',fontsize=18)\n",
        "xlabel(\"FPR\", fontsize=20)\n",
        "ylabel(\"TPR\", fontsize=20)\n",
        "xlim(0,1)\n",
        "ylim(0,1)\n",
        "plot(fpr_DL,tpr_DL,linewidth=3,color='red',label='CNN')\n",
        "\n",
        "legend(fontsize=14)\n",
        "\n",
        "\n",
        "# Precision Recall curve (False positive rate vs. True positive rate)\n",
        "precision_DL, recall_DL, thresholds_DL = precision_recall_curve(t_test, Y_pred_DL)\n",
        "\n",
        "#plot PR curve\n",
        "fig = plt.figure()\n",
        "title('P-R curve',fontsize=18)\n",
        "xlabel(\"Precision\", fontsize=20)\n",
        "ylabel(\"Recall\", fontsize=20)\n",
        "xlim(0,1)\n",
        "ylim(0,1)\n",
        "plot(precision_DL,recall_DL,linewidth=3,color='red',label='CNN')\n",
        "legend(fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8B5LNsyTuPY"
      },
      "source": [
        "The follwing cells visualize some random examples of bad classifications in order to explore what the network has understood. If you run multiple times the examples will change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEml6NaOT_Sj"
      },
      "source": [
        "### Bad classifications of CNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjiZtz61H_cY"
      },
      "source": [
        "# objects classifed as early-types by the CNN but visually classifed as late-types\n",
        "bad = np.where((Y_pred_DL[:,0]<0.5)&(t_test==1))\n",
        "randomized_inds_train = np.random.permutation(bad)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle(\"Galaxies visually classifed as Class1 but classified as Class0\",fontsize=10)\n",
        "for i,j in zip(randomized_inds_train[0][0:4],range(4)):\n",
        "  ax = fig.add_subplot(2, 2, j+1)\n",
        "  im = ax.imshow(x_test[i,:,:])\n",
        "  plt.title('$Morph$='+str(t_test[i]))\n",
        "  fig.tight_layout()\n",
        "  fig.colorbar(im)\n",
        "\n",
        "\n",
        "\n",
        "# objects classifed as late-types by the CNN but visually classifed as early-types\n",
        "bad2 = np.where((Y_pred_DL[:,0]>0.5)&(t_test==0))\n",
        "randomized_inds_train = np.random.permutation(bad2)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle(\"Galaxies visually classifed as Class0 but classified as Class1\",fontsize=10)\n",
        "for i,j in zip(randomized_inds_train[0][0:4],range(4)):\n",
        "  ax = fig.add_subplot(2, 2, j+1)\n",
        "  im = ax.imshow(x_test[i,:,:])\n",
        "  plt.title('$Morph$='+str(t_test[i]))\n",
        "  fig.tight_layout()\n",
        "  fig.colorbar(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHmlEvdtUlVl"
      },
      "source": [
        "## Exercices\n",
        "\n",
        "1. Can you estimate the epistemic uncertainty of the model using MC dropout?\n",
        "\n",
        "2. If you wish: repeat steps above with E/S0 separation, compare to RFs and ANNs."
      ]
    }
  ]
}