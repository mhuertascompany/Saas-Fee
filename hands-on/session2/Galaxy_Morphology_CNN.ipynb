{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Galaxy_Morphology_CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuertascompany/Saas-Fee/blob/main/hands-on/session2/Galaxy_Morphology_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jatIhJ9KJQV"
      },
      "source": [
        "#Galaxy Morphology with \"classical ML\" and deep learning\n",
        "\n",
        "The goal of this tutorial is to illustrate a very basic supervised binary classification with different ML approaches. The goal is to setup a ML algorithm to determine the visual morphological type of nearby galaxies from the Sloan Digital Sky Survey. The first deep learning papers in Astronomy addressed this problem at low and high redshift (Dielemann+15, Huertas-Company+15).\n",
        "\n",
        "![](https://drive.google.com/uc?id=1TaiRB1wxui4AKnhuF4iH4LJkmrlb-D6d)\n",
        "\n",
        "The notebook illustrates first how to train a Random Forest and an Artifical Neural Network using catalog parameters (Stellar Mass and Color). The ML models are taken from scikitlearn.\n",
        "\n",
        "Then we use a Convolutional Neural Network (deep learning) to learn the features directly from the images with no catalog information. The CNN  model is implemented here with Keras and a TensorFlow backend.  We use as training set, the visually classified sample of ~14,000 galaxies by Nair&Abraham. For illustration purposes, we use jpeg RGB images as input. However the same methodology can be applied to fits.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#### Before we start, make sure to open this Colab notebook in \"PlayGround Mode\" (top left) and to change the Runtime type to GPU by navigating to the toolbar and clicking Runtime -> Change runtime type and then changing Hardware accelerator to GPU\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpv-XO8Sxgvi"
      },
      "source": [
        "import numpy as np\n",
        "from astropy.io import fits\n",
        "from astropy.table import Table\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.normalization import  BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, accuracy_score,auc\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PqZCKlVSMJ"
      },
      "source": [
        "## Mount Drive\n",
        "\n",
        "Before mounting the drive click on [this folder](https://drive.google.com/drive/folders/1PcftgBzBySo1Ync-Wdsp9arTCJ_MfEPE?usp=sharing) and add it to your google drive by following these steps:\n",
        "\n",
        "*   Go to your drive \n",
        "*   Find shared folder (\"Shared with me\" link)\n",
        "*   Right click it\n",
        "*   Click Add to My Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Io82GXlCNdF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqPFZXvf1FNs"
      },
      "source": [
        "---\n",
        "#### The notenook is setup to illustrate 2 different classifications:\n",
        "\n",
        "\n",
        "#### 1.   Early vs. Late: This is an easy example in which we only try to separate between early-type and late-type galaxies.\n",
        "\n",
        "#### 2.   E vs. S0: The second example is more challenging. We try to separate ellipticals from S0s.\n",
        "\n",
        "#### By default case 1 is turn on. In order to switch to case 2 set the variable CLASS_EARLY_LATE to False.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM9KbCzH21D_"
      },
      "source": [
        "CLASS_EARLY_LATE=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A5hM83EeiH5"
      },
      "source": [
        "## Deep Learning (CNN)\n",
        "This section illustrates how to use a Convolutional Neural Network to estimate the visual morphology. The input of the network are now the images themselves without parameters. The CNN then automatically extracts the features. This is the main difference between classical and deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OErN1Sb5enXV"
      },
      "source": [
        "### Data Download and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhIqCwEg9UUd"
      },
      "source": [
        "if CLASS_EARLY_LATE:\n",
        "  #Load data\n",
        "  pathinData=\"/content/drive/My Drive/EDE2019/morphology\"\n",
        "\n",
        "  #images\n",
        "  X = np.load(pathinData+'/image_vector_E_S_10000.npy')\n",
        "  #morphological class\n",
        "  Y = np.load(pathinData+'/target_vector_E_S_10000.npy') \n",
        "\n",
        "else:\n",
        "  #Load data\n",
        "  pathinData=\"/content/drive/My Drive/EDE2019/morphology\"\n",
        "\n",
        "  #images\n",
        "  X = np.load(pathinData+'/image_vector_E_S0_5250.npy')\n",
        "  #morphological class\n",
        "  Y = np.load(pathinData+'/target_vector_E_S0_5250.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7JrTFYZz96c"
      },
      "source": [
        "# Spliting in Training and Test datasets, 4/5 of galaxies for training, 1/5 for testing\n",
        "x_train = X[0:len(X)//5*4,:,:,:]   \n",
        "x_test = X[len(X)//5*4:,:,:,:]\n",
        "t_train = Y[0:len(Y)//5*4]\n",
        "t_test = Y[len(Y)//5*4:]\n",
        "print ('Y_train.shape= ', t_train.shape)          \n",
        "print(np.max(t_train),np.min(t_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c80101gQ5f2J"
      },
      "source": [
        "### Visualization of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKdVzDtN3dkw"
      },
      "source": [
        "randomized_inds_train = np.random.permutation(len(x_train))\n",
        "\n",
        "fig = plt.figure()\n",
        "for i,j in zip(randomized_inds_train[0:4],range(4)):\n",
        "  ax = fig.add_subplot(2, 2, j+1)\n",
        "  im = ax.imshow(x_train[i,:,:].astype(int))\n",
        "  plt.title('$Morph$='+str(t_train[i]))\n",
        "  fig.tight_layout() \n",
        "  fig.colorbar(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8HpW3HM5mAP"
      },
      "source": [
        "### Pre-processing of images (Normlaziation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lIPKj4l_rXQ"
      },
      "source": [
        "mu = np.amax(x_train,axis=(1,2))\n",
        "for i in range(0,mu.shape[0]):\n",
        "    x_train[i,:,:,0] = x_train[i,:,:,0]/mu[i,0]\n",
        "    x_train[i,:,:,1] = x_train[i,:,:,1]/mu[i,1]\n",
        "    x_train[i,:,:,2] = x_train[i,:,:,2]/mu[i,2]\n",
        "    \n",
        "mu_test = np.amax(x_test,axis=(1,2))\n",
        "for i in range(0,mu_test.shape[0]):\n",
        "    x_test[i,:,:,0] = x_test[i,:,:,0]/mu_test[i,0]\n",
        "    x_test[i,:,:,1] = x_test[i,:,:,1]/mu_test[i,1]\n",
        "    x_test[i,:,:,2] = x_test[i,:,:,2]/mu_test[i,2]    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8H-WZHXLlK4"
      },
      "source": [
        "### Model definition\n",
        "The following cell defines the model architecture. There is a Convolutional part made of multiple convolutinal layers with differnet depths and filter sizes. MaxPooling are used to reduce the sizes of tensors as we go deeper into the network. Batch Normalization and Dropout are use at the training phase to reduce over fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx-BT4zM348O"
      },
      "source": [
        "## THIS IS THE MAIN CELL TO DEFINE A CONVOLUTIONAL MODEL\n",
        "## FELL FREE TO EDIT / CHANGE / ADD LAYERS\n",
        "## AS IT IS NOW IT CONTAINS ONLY ONE COVOLUTIONAL LAYER\n",
        "\n",
        "def CNN_Nair(img_channels, img_rows, img_cols):\n",
        "    \n",
        "    # some hyperparamters you can chage\n",
        "    dropoutpar=0.5\n",
        "    depth=16   \n",
        "    nb_dense = 64\n",
        "    \n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(32, 6,6, activation='relu',padding='same',input_shape=(img_rows, img_cols,img_channels)))\n",
        "   \n",
        "    model.add(BatchNormalization())  ## batch normalization layer\n",
        "\n",
        "    ## ADD LAYERS / CONVOLUTIONS HERE\n",
        "    \n",
        "    ## FROM HERE IS THE FULLY CONNECTED PART OF THE MODEL. YOU CAN ALSO CHANGE THIS\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(nb_dense, activation='relu'))\n",
        "    model.add(Dropout(dropoutpar)) \n",
        "\n",
        "    ## OUTPUT LAYER -- DO NOT CHANGE\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))  \n",
        "\n",
        "    # COMPILES THE MODEL. WE USE CROSS-ENTROPY LOSS. YOU CAN CHANGE THE OPTIMIZER\n",
        "    # IF NEEDED\n",
        "    print(\"Compilation...\")\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    print(\"... done!\")\n",
        "    print(\"Model Summary\")\n",
        "    print(\"===================\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFKDX1PtP4x7"
      },
      "source": [
        "This cell is to delete prevois runs if needed. Only run if you want to delete the results from previous runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FO8dzy8DdQY"
      },
      "source": [
        "RESET=True\n",
        "if RESET:\n",
        "  os.system(\"rm -r \"+pathout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XXrhdl-RHaj"
      },
      "source": [
        "Run this cell to launch a TensorBoard panel which will allow to follow the progress of the training of the deep neural network. Just run the cell and you should see an orange panel appearing. If not try again a second time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbnGMY9s7e4l"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir morphology/models/cnn1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjEmToBYRaJJ"
      },
      "source": [
        "Main code for training the CNN model defined previously. All outputs are stored in pathout. Change if you want to keep different models. BY default the dataset is augmented to reduce overfitting. You can turn it off be setting data_augmentation to False."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gh5bQhF98Gq"
      },
      "source": [
        "# train params - hardocded for simplicity - you can change them\n",
        "pathout='morphology/models/model1' #output folder to store the results\n",
        "model_name = '/cnn1'  #name of the final model which is saved in pathout\n",
        "\n",
        "LOAD_MODEL=False\n",
        "\n",
        "batch_size = 32 \n",
        "nb_epoch = 20  #number of iterations for training - Can be changed\n",
        "data_augmentation = True # if set to True the data will be augmented at every iteration\n",
        "\n",
        "\n",
        "    \n",
        "# input image dimensions\n",
        "img_rows, img_cols = x_train.shape[1:3]\n",
        "img_channels = 3\n",
        "\n",
        "#Avoid more iterations once convergence\n",
        "patience_par=10\n",
        "earlystopping = EarlyStopping(monitor='val_loss',patience = patience_par,verbose=0,mode='auto' )\n",
        "modelcheckpoint = ModelCheckpoint(pathout+model_name+\"_best.hd5\",monitor='val_loss',verbose=0,save_best_only=True)\n",
        "tensorboard = TensorBoard(log_dir=pathout)\n",
        "\n",
        "#build model\n",
        "cnn=CNN_Nair(img_channels, img_rows, img_cols)\n",
        "if LOAD_MODEL:\n",
        "  cnn.load_weights(pathout+model_name+'.hd5')\n",
        "\n",
        "\n",
        "if not data_augmentation:\n",
        "  print('Not using data augmentation.')\n",
        "  history = cnn.fit(x_train, t_train,\n",
        "                            batch_size=batch_size,\n",
        "                            nb_epoch=nb_epoch,\n",
        "                            validation_data=(x_test, t_test),\n",
        "                            shuffle=True,\n",
        "                            verbose=verbose, callbacks=[earlystopping, modelcheckpoint,tensorboard])\n",
        "else:\n",
        "  print('Using real-time data augmentation.')\n",
        "\n",
        "  # this will do preprocessing and realtime data augmentation. FEEL FREE TO\n",
        "  # CHANGE THE PARAMETERS AND SEE THE EFFECTS\n",
        "  datagen = ImageDataGenerator(\n",
        "            featurewise_center=False, \n",
        "            samplewise_center=False, \n",
        "            featurewise_std_normalization=False, \n",
        "            samplewise_std_normalization=False,\n",
        "            zca_whitening=False, \n",
        "            rotation_range=25,\n",
        "            width_shift_range=0.1,  \n",
        "            height_shift_range=0.1, \n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            zoom_range=[0.75,1.3])  \n",
        "\n",
        "        \n",
        "  datagen.fit(x_train)\n",
        "        \n",
        "  history = cnn.fit_generator(\n",
        "                    datagen.flow(x_train, t_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=batch_size,\n",
        "                    epochs=nb_epoch,\n",
        "                    validation_data=(x_test, t_test),\n",
        "                    callbacks=[ earlystopping, modelcheckpoint,tensorboard]\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "print(\"Saving model...\")\n",
        "cnn.save_weights(pathout+model_name+\".hd5\",overwrite=True)\n",
        "    \n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6jXNmKDGcyo"
      },
      "source": [
        "## Predictions and comparisons of different approaches\n",
        "The following cells use the trained models (RF,ANN and CNN) to predict the morphological class of the test dataset and compare the performance of the different algorithms. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFpihOh0FuN2"
      },
      "source": [
        "print(\"Predicting...\")\n",
        "print(\"====================\")\n",
        "LOAD_MODEL=False\n",
        "if LOAD_MODEL:\n",
        "  cnn = tf.keras.models.load_model(pathout+model_name+\".hd5\")\n",
        "\n",
        "Y_pred_DL = cnn.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXKSAhBqSX2g"
      },
      "source": [
        "We now compute the global accuracy as well as ROC and P-R curves. If you are not familiar with these curves please see the lecture slides or click [here](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svvKwV-AGpYB"
      },
      "source": [
        "#global accuracy\n",
        "\n",
        "## TRY DIFFERENT MODELS - SEE THE EFFECTS ON THE FINAL ROC CURVES\n",
        "\n",
        "## ASSESMENT:: COMPARE IN A UNIQUE NOTEBOOK THE 3 METHODS WE HAVE SEEN\n",
        "## COMMENT \n",
        "\n",
        "\n",
        "Y_pred_DL_class=Y_pred_DL*0\n",
        "Y_pred_DL_class[Y_pred_DL>0.5]=1\n",
        "\n",
        "print(\"Global Accuracy CNN:\", accuracy_score(t_test, Y_pred_DL_class))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ROC curve (False positive rate vs. True positive rate)\n",
        "fpr_DL, tpr_DL, thresholds_DL = roc_curve(t_test, Y_pred_DL)\n",
        "\n",
        "print(\"AUC CNN:\", auc(fpr_DL, tpr_DL))\n",
        "\n",
        "#plot ROC\n",
        "fig = plt.figure() \n",
        "title('ROC curve',fontsize=18)\n",
        "xlabel(\"FPR\", fontsize=20)\n",
        "ylabel(\"TPR\", fontsize=20)\n",
        "xlim(0,1)\n",
        "ylim(0,1)\n",
        "plot(fpr_DL,tpr_DL,linewidth=3,color='red',label='CNN')\n",
        "\n",
        "legend(fontsize=14)\n",
        "\n",
        "\n",
        "# Precision Recall curve (False positive rate vs. True positive rate)\n",
        "precision_DL, recall_DL, thresholds_DL = precision_recall_curve(t_test, Y_pred_DL)\n",
        "\n",
        "#plot PR curve\n",
        "fig = plt.figure() \n",
        "title('P-R curve',fontsize=18)\n",
        "xlabel(\"Precision\", fontsize=20)\n",
        "ylabel(\"Recall\", fontsize=20)\n",
        "xlim(0,1)\n",
        "ylim(0,1)\n",
        "plot(precision_DL,recall_DL,linewidth=3,color='red',label='CNN')\n",
        "legend(fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8B5LNsyTuPY"
      },
      "source": [
        "The follwing cells visualize some random examples of bad classifications in order to explore what the network has understood. If you run multiple times the examples will change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEml6NaOT_Sj"
      },
      "source": [
        "### Bad classifications of CNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjiZtz61H_cY"
      },
      "source": [
        "# objects classifed as early-types by the CNN but visually classifed as late-types\n",
        "bad = np.where((Y_pred_DL[:,0]<0.5)&(t_test==1))\n",
        "randomized_inds_train = np.random.permutation(bad)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle(\"Galaxies visually classifed as Class1 but classified as Class0\",fontsize=10)\n",
        "for i,j in zip(randomized_inds_train[0][0:4],range(4)):\n",
        "  ax = fig.add_subplot(2, 2, j+1)\n",
        "  im = ax.imshow(x_test[i,:,:])\n",
        "  plt.title('$Morph$='+str(t_test[i]))\n",
        "  fig.tight_layout() \n",
        "  fig.colorbar(im)\n",
        "\n",
        "\n",
        "\n",
        "# objects classifed as late-types by the CNN but visually classifed as early-types\n",
        "bad2 = np.where((Y_pred_DL[:,0]>0.5)&(t_test==0))\n",
        "randomized_inds_train = np.random.permutation(bad2)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle(\"Galaxies visually classifed as Class0 but classified as Class1\",fontsize=10)\n",
        "for i,j in zip(randomized_inds_train[0][0:4],range(4)):\n",
        "  ax = fig.add_subplot(2, 2, j+1)\n",
        "  im = ax.imshow(x_test[i,:,:])\n",
        "  plt.title('$Morph$='+str(t_test[i]))\n",
        "  fig.tight_layout() \n",
        "  fig.colorbar(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}